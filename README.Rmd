---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# stepdownfdp

<!-- badges: start -->
<!-- badges: end -->

This package provides functionality to convert a collection of 
target/decoy scores, obtained from competition-based statistical procedures, 
to a list of rejections. In this list of rejections, the proportion of false
discoveries is bounded by a prespecified tolerance $\alpha \in (0, 1)$ with 
probability at least $1 - \gamma \in (0, 1)$.

## Installation

You can install the development version of stepdownfdp from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("uni-Arya/stepdownfdp")
```

## Usage

### With a single decoy

For use in a single-decoy experiment, the user needs to specify a
collection of target/decoy scores for each hypothesis, an FDP threshold 
$\alpha \in (0, 1)$, and a confidence level $\gamma \in (0, 1)$.

We first use `mirandom` to convert target/decoy scores into winning scores
and labels. For input, the argument `scores` is required to be
an $m \times 2$ matrix, where $m$ is the number of hypotheses. Note: it is important to make sure that the first column of `scores` corresponds to target scores.

```{r mirandom-single}
library(stepdownfdp)
set.seed(123)
target_scores     <- rnorm(200, mean = 1.75)
decoy_scores      <- rnorm(200, mean = 0)
scores            <- cbind(target_scores, decoy_scores)
scores_and_labels <- mirandom(scores)
head(scores_and_labels)
```

After obtaining the output from `mirandom` we can pass it through
`fdp_sd` to return the winning scores and indices of hypotheses that were
rejected. Note that the output is ordered in decreasing order of winning scores.

```{r fdp_sd-single}
results  <- fdp_sd(scores_and_labels, alpha = 0.1, conf = 0.1)
W_scores <- results$discoveries
indices  <- results$discoveries_ind
W_scores
indices
```

### With multiple decoys

For use in a multiple-decoy experiment, the user needs to specify, in addition, parameters $c \leq \lambda$ of the form $k/(d + 1)$ where $d$ is the total number of decoy scores used for each hypothesis and $1 \leq k \leq d$ is an integer. As an example, if we compute $3$ decoy scores for each hypothesis, we may take $c$ to be $1/4$, $1/2$, or $3/4$. The value of $c$ determines the rank in which the target score may fall to be considered "winning." E.g., if $c = 1/4$, $H_i$ is labelled as a target win whenever its corresponding target score is the highest ranked score among all targets/decoys for that hypothesis.

The argument `scores` is now required to be an $m \times (d + 1)$ matrix, where $m$ is the number of hypotheses and $d$ is the number of decoy scores for each. As in the single-decoy case, the first column must consist of target scores.

```{r mirandom-multiple}
library(stepdownfdp)
set.seed(123)
target_scores     <- rnorm(200, mean = 1.75)
decoy_scores      <- matrix(rnorm(600, mean = 0), ncol = 3)
scores            <- cbind(target_scores, decoy_scores)
scores_and_labels <- mirandom(scores, c = 0.25, 0.75)
head(scores_and_labels)
```

Make sure to pass the same $c$ and $\lambda$ values to `fdp_sd`.

```{r fdp_sd-multiple}
results  <- fdp_sd(scores_and_labels, alpha = 0.1, conf = 0.1, c = 0.25, lambda = 0.75)
W_scores <- results$discoveries
indices  <- results$discoveries_ind
W_scores
indices
```


### Randomised versions

The user can also invoke the randomised version of both single-decoy and multiple-decoy procedures by passing `procedure = "coinflip"` into `fdp_sd`.

```{r fdp_sd-randomised}
results  <- fdp_sd(scores_and_labels, alpha = 0.1, conf = 0.1, c = 0.25, lambda = 0.75, 
                   procedure = "coinflip")
W_scores <- results$discoveries
indices  <- results$discoveries_ind
W_scores
indices
```
